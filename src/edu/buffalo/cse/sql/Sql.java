/* Generated By:JavaCC: Do not edit this line. Sql.java */
package edu.buffalo.cse.sql;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

import edu.buffalo.cse.sql.Schema.Column;
import edu.buffalo.cse.sql.data.Datum;
import edu.buffalo.cse.sql.data.Datum.CastError;
import edu.buffalo.cse.sql.data.Datum.Flt;
import edu.buffalo.cse.sql.plan.*;
import edu.buffalo.cse.sql.plan.AggregateNode.AggColumn;
import edu.buffalo.cse.sql.plan.PlanNode.*;

public class Sql {

	public static void main(String[] args) {
		System.out.println("You haven't implemented me yet!");
	}

	public static List<Datum[]> execQuery(
			Map<String, Schema.TableFromFile> tables, PlanNode q)
			throws SqlException {
		System.out.println("Something");
		System.out.println("Processing the Q: " + q.toString());
		boolean a = tables.containsKey("R");
		System.out.println("R is the key present " + a);
		// for (Map.Entry<String, Schema.TableFromFile> iterator : tables
		// .entrySet()) {
		// File file = iterator.getValue().getFile(); // read file for data
		// System.out.println("File name is " + file.toString());
		//
		// TupleIterator tblItr = new TupleIterator(iterator.getValue());
		//
		// Datum[] tuple;
		// while (tblItr.hasNext()) {
		// tuple = tblItr.readNext();
		// System.out.println(tuple);
		//
		// }
		// }
		QueryRead queRead = new QueryRead(tables);
		List<Datum[]> res = queRead.QueryEval(q);
		// Schema.Column tableColumns =

		// throw new SqlException("execQuery() is unimplemented");
		return res;
	}

	public static List<List<Datum[]>> execFile(File program)
			throws SqlException {
		throw new SqlException("execQuery() is unimplemented");
	}
}

class TupleIterator {
	File file;
	Schema.TableFromFile schema;
	int index;
	String[] data;
	int readidx;
	Datum[] array;
	BufferedReader CSVFile;

	public TupleIterator(Schema.TableFromFile schema) {
		file = schema.getFile();
		this.schema = schema;

		String filePath = file.toString();
		try {
			CSVFile = new BufferedReader(new FileReader(filePath));

		} catch (IOException e) {

		}
	}

	public Boolean hasNext() {
		if (CSVFile.markSupported()) {
			System.out.println("Mark is supported");
			try {
				CSVFile.mark((int) file.length());
				if (CSVFile.readLine() != null) {
					CSVFile.reset();
					return true;
				}
			} catch (IOException e) {

			}
		}
		return false;
	}

	public Datum[] readNext() {

		String dataRow = null;
		try {
			if (CSVFile != null) {
				dataRow = CSVFile.readLine();
				if (dataRow == null) {
					CSVFile.close();
					return null;
				}
			}
		} catch (IOException e) {

		}
		// split the file
		// File fd = new File(file);
		String[] dataArr = dataRow.split(","); // also remove the white spaces
		Datum[] tuple = new Datum[dataArr.length]; // for reading tuple
		int idx = 0;
		for (Schema.Column c : schema) {
			Datum data;
			switch (c.type) {
			case INT:
				// get int from ParseInt.String[index]
				data = new Datum.Int(Integer.parseInt(dataArr[idx]));
				tuple[idx] = data;
				idx++;
				break;
			case BOOL:
				data = new Datum.Bool(Boolean.parseBoolean(dataArr[idx]));
				tuple[idx] = data;
				idx++;
				break;
			case FLOAT:
				data = new Datum.Flt(Float.parseFloat(dataArr[idx]));
				tuple[idx] = data;
				idx++;
				break;
			case DATE:
				data = new Datum.Str(dataArr[idx]);
				tuple[idx] = data;
				idx++;
				break;
			case STRING:
				data = new Datum.Str(dataArr[idx]);
				tuple[idx] = data;
				idx++;
				break;
			default:
				break;
			}
		}
		if (idx == dataArr.length) {
			System.out.println("Read tuple is correct");
		}
		return tuple;
	}

	public void closeFile() {
		if (CSVFile != null) {
			try {
				CSVFile.close();
			} catch (IOException e) {

			}
		}

	}

}

class QueryRead {
	Map<String, Schema.TableFromFile> db;

	public QueryRead(Map<String, Schema.TableFromFile> tables) {
		db = tables;
	}

	public List<Datum[]> QueryEval(PlanNode q) {
		List<Datum[]> res = null, left=null, right=null;
		switch (q.struct) {
		case BINARY:
			Binary bchild = (Binary) q;
			left = this.QueryEval(bchild.getLHS());
			right = this.QueryEval(bchild.getRHS());
			break;
		case UNARY:
			Unary uchild = (Unary) q;
			res = this.QueryEval(uchild.getChild());
			break;
		case LEAF:
			break;
		default:
			System.out.println("Wrong Structure");
			break;
		}
		switch (q.type) {
		case PROJECT:
			System.out.println("Project Query");
			break;
		case SELECT:
			System.out.println("Select Query");
			break;
		case SCAN:
			Scan sc = new Scan();
			res = sc.scanTable(db, (ScanNode) q);
			System.out.println("Scan Query");
			break;
		case JOIN:
			Join j = new Join();
			res = j.joinTables(left, right, (JoinNode) q);
			System.out.println("Join Query");
			break;
		case NULLSOURCE:
			System.out.println("Nullsource Query");
			break;
		case UNION:
			System.out.println("Union Query");
			break;
		case AGGREGATE:
			Aggregate ag = new Aggregate();
			res = ag.getAggregate(res, (AggregateNode) q, db);
			System.out.println("Aggregate Query");
			break;
		default:
			System.out.println("Error in type");
			break;
		}
		return res;
	}
}

class Scan {
	public List<Datum[]> scanTable(Map<String, Schema.TableFromFile> tables,
			ScanNode q) {
		List<Datum[]> db = new ArrayList<Datum[]>();
		for (Map.Entry<String, Schema.TableFromFile> iterator : tables
				.entrySet()) {
			if (q.table == iterator.getKey()) {
				File file = iterator.getValue().getFile(); // read file for data
				System.out.println("File name is " + file.toString());

				TupleIterator tblItr = new TupleIterator(iterator.getValue());

				Datum[] tuple;
				while (tblItr.hasNext()) {
					tuple = tblItr.readNext();
					System.out.println(tuple);
					db.add(tuple);
				}
				break;
			}
		}
		return db;
	}
}

class Aggregate {
	public List<Datum[]> getAggregate(List<Datum[]> inp, AggregateNode aNode,
			Map<String, Schema.TableFromFile> db) {
		List<AggColumn> cols;
		List<Datum[]> res = new ArrayList<Datum[]>();
		cols = aNode.getAggregates();
		int index = 0;
		// facing issues here
		for (int i = 0; i < cols.size(); i++) {
			ExprTree exp = cols.get(i).expr;
			int match = 0;
			Column c = new Column(null, null, null);
			for (Map.Entry<String, Schema.TableFromFile> iterator : db
					.entrySet()) {
				Schema.TableFromFile value = iterator.getValue();
				for (index = 0; index < value.size(); index++) {
					String vname1 = exp.toString();
					String vname2 = value.get(index).name.name;
					if (vname1.equals(vname2)) {
						match = 1;
						c = value.get(index);
						break;
					}
				}
				if (match == 1)
					break;
			}
			float ans = 0;

			switch (cols.get(i).aggType) {
			case SUM:
				for (Datum[] d : inp) {
					try {
						ans = ans + d[index].toFloat();
					} catch (CastError e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
				Datum d = null;
				switch (c.type) {
				case INT:
					d = new Datum.Int((int) ans);
					break;
				case FLOAT:
					d = new Datum.Flt(ans);
					break;
				}
				Datum[] dSum = new Datum[1];
				dSum[0] = d;
				res.add(dSum);
				break;
			case COUNT:
				int cn = 0;
				for (Datum[] count : inp) {
					cn++;
				}
				Datum count = new Datum.Int(cn);
				Datum[] dCount = new Datum[1];
				dCount[0] = count;
				res.add(dCount);
				break;
			case AVG:
				cn = 0;
				for (Datum[] avg : inp) {
					try {
						ans = ans + avg[index].toFloat();
						cn++;
					} catch (CastError e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
				Datum avg = new Datum.Flt(ans / cn);
				Datum[] dAvg = new Datum[1];
				dAvg[0] = avg;
				res.add(dAvg);
				break;
			case MIN:
				cn = 0;
				for (Datum[] min : inp) {
					try {
						if (cn == 0)
							ans = min[index].toFloat();
						else if (ans > min[index].toFloat())
							ans = min[index].toFloat();
						cn++;
					} catch (CastError e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
				Datum min = null;
				switch (c.type) {
				case INT:
					min = new Datum.Int((int) ans);
					break;
				case FLOAT:
					min = new Datum.Flt(ans);
					break;
				}
				Datum[] dMin = new Datum[1];
				dMin[0] = min;
				res.add(dMin);
				break;
			case MAX:
				cn = 0;
				for (Datum[] max : inp) {
					try {
						if (cn == 0)
							ans = max[index].toFloat();
						if (ans < max[index].toFloat())
							ans = max[index].toFloat();
						cn++;
					} catch (CastError e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
				Datum max = null;
				switch (c.type) {
				case INT:
					max = new Datum.Int((int) ans);
					break;
				case FLOAT:
					max = new Datum.Flt(ans);
					break;
				}
				Datum[] dMax = new Datum[1];
				dMax[0] = max;
				res.add(dMax);
				break;
			}

		}
		return res;
	}
}

class Join {
	public List<Datum[]> joinTables(List<Datum[]> left, List<Datum[]> right,
			JoinNode q) {
		List<Datum[]> res = new ArrayList<Datum[]>();

		return res;
	}
}